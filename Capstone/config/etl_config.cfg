[AWS]
aws_secret_access_key =
aws_access_key_id =
aws_region = us-west-2

[S3]
s3_bucket = immigrations-analytics1
s3_sas_key = 18-83510-I94-Data-2016/
s3_csv_key = data/
s3_dict_key = dictionary/
s3_output_key = output/
airports_file = airport-codes.csv
us_demographics_file = us-cities-demographics.csv
dictionary_file = I94_SAS_Labels_Descriptions.SAS
s3_log_key = log/
s3_scripts_key = scripts/
s3_config_key = config/
input_files = ["i94_apr16_sub.sas7bdat"]
output_dir = output/

[DOCKER]
# base_dir = /usr/local
base_dir = /usr/local/airflow
data_dir = data
dict_dir = dictionary
config_dir = config
scripts_dir = scripts
sas_data_dir = 18-83510-I94-Data-2016
input_files = ["i94_apr16_sub.sas7bdat"]
airports_file = airport-codes.csv
us_demographics_file = us-cities-demographics.csv
dictionary_file = I94_SAS_Labels_Descriptions.SAS
log_dir = log
log_file = etl_logging_
output_dir = output

[HADOOP]
base_dir = /home/hadoop
log_dir = log
log_file = etl_logging_

[LOCAL]
base_dir = /Users/home/Documents/dend/Data-Engineering-ND/Capstone
data_dir = data
dict_dir = dictionary
config_dir = config
scripts_dir = scripts
sas_data_dir = 18-83510-I94-Data-2016
input_files = ["i94_apr16_sub.sas7bdat"]
airports_file = airport-codes.csv
us_demographics_file = us-cities-demographics.csv
dictionary_file = I94_SAS_Labels_Descriptions.SAS
log_dir = log
log_file = etl_logging_
output_dir = output
dq_log_file = dq_logging_

[APP]
jar_dir = jars
sas_jar_ver = saurfang:spark-sas7bdat:3.0.0-s_2.12.jar

[DQ]
tables = '["i94_visa", "i94_travel_mode"]'
table_col = '{"i94_visa": ["visa_id"], "i94_travel_mode": ["mode_id"]}'


